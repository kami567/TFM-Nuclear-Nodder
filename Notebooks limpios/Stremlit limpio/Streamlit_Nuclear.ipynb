{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Este es el codigo que se ejecuta en streamlit en formato Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Librer√≠as b√°sicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import joblib\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import streamlit as st\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# An√°lisis y estad√≠sticas\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from scipy import stats\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# Machine Learning y preprocesamiento\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Forecasting con Skforecast\n",
    "import skforecast\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.recursive import ForecasterRecursive\n",
    "from skforecast.direct import ForecasterDirect\n",
    "from skforecast.model_selection import TimeSeriesFold, grid_search_forecaster, backtesting_forecaster\n",
    "from skforecast.preprocessing import RollingFeatures\n",
    "from skforecast.utils import save_forecaster, load_forecaster\n",
    "\n",
    "# Interpretabilidad de modelos\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fecha_actual = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "st.write(\"Fecha actual:\", fecha_actual)\n",
    "\n",
    "# Definir las rutas base\n",
    "ruta_sin_procesar = os.path.join(\"Datos\", \"Datos Sin Procesar\", fecha_actual)\n",
    "ruta_procesados = os.path.join(\"Datos\", \"Datos Procesados\", fecha_actual)\n",
    "\n",
    "# URL del archivo por defecto en GitHub\n",
    "url_tabla = \"https://raw.githubusercontent.com/kami567/TFM-Nuclear-Nodder/main/Table_8.1_Nuclear_Energy_Overview.xlsx\"\n",
    "# URL del scaler en GitHub (corrigiendo la ruta)\n",
    "url_scaler = \"https://raw.githubusercontent.com/kami567/TFM-Nuclear-Nodder/main/scalers.pkl\"\n",
    "# Definir las URLs de los modelos en GitHub\n",
    "url_sarimax_mw = \"https://raw.githubusercontent.com/kami567/TFM-Nuclear-Nodder/main/SARIMAX_Net_Summer_Capacity_MW.joblib\"\n",
    "url_sarimax_capacity = \"https://raw.githubusercontent.com/kami567/TFM-Nuclear-Nodder/main/SARIMAX_Capacity_Factor_Percent.joblib\"\n",
    "url_ridge = \"https://raw.githubusercontent.com/kami567/TFM-Nuclear-Nodder/main/modelo_ridge_NetGeneration.pkl\"\n",
    "\n",
    "# Directorios para guardar archivos localmente antes del commit en GitHub\n",
    "ruta_sin_procesar = \"archivos_sin_procesar\"\n",
    "ruta_procesados = \"archivos_procesados\"\n",
    "\n",
    "# Preguntar al usuario si quiere cargar desde GitHub o subir manualmente\n",
    "use_github = st.radio(\n",
    "    \"¬øC√≥mo quieres cargar el archivo?\",\n",
    "    (\"Usar archivo por defecto de GitHub\", \"Subir un archivo propio\")\n",
    ")\n",
    "\n",
    "if use_github == \"Usar archivo por defecto de GitHub\":\n",
    "    # Cargar el archivo desde la URL\n",
    "    excel_data = pd.ExcelFile(url_tabla, engine=\"openpyxl\")\n",
    "    st.write(\"Archivo cargado desde GitHub\")\n",
    "else:\n",
    "    # Permitir la subida del archivo\n",
    "    uploaded_file = st.file_uploader(\"Sube un archivo Excel\", type=[\"xlsx\"])\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        excel_data = pd.ExcelFile(uploaded_file)\n",
    "        st.write(\"Archivo cargado desde el usuario\")\n",
    "    else:\n",
    "        st.warning(\"Por favor, sube un archivo para continuar.\")\n",
    "        st.stop()\n",
    "\n",
    "# Mostrar las hojas disponibles y permitir al usuario elegir\n",
    "sheet_name = st.selectbox(\"Selecciona la hoja de datos mensuales\", excel_data.sheet_names)\n",
    "\n",
    "# Cargar la hoja seleccionada\n",
    "df = pd.read_excel(excel_data, sheet_name=sheet_name)\n",
    "\n",
    "# Limpiar y procesar los datos\n",
    "monthly_data_clean = df.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "# Definir los encabezados de las columnas\n",
    "column_headers = [\n",
    "    \"Date\",\n",
    "    \"Total_Operable_Units\",\n",
    "    \"Net_Summer_Capacity_MW\",\n",
    "    \"Net_Generation_MWh\",\n",
    "    \"Share_of_Electricity_Percent\",\n",
    "    \"Capacity_Factor_Percent\"\n",
    "]\n",
    "\n",
    "# Extraer datos v√°lidos\n",
    "monthly_data_extracted = monthly_data_clean.iloc[7:].reset_index(drop=True)\n",
    "monthly_data_extracted.columns = column_headers\n",
    "\n",
    "# Convertir la columna de fecha a formato datetime\n",
    "monthly_data_extracted['Date'] = pd.to_datetime(monthly_data_extracted['Date'], errors='coerce')\n",
    "monthly_data_extracted['Date'] = monthly_data_extracted['Date'].dt.to_period('M')\n",
    "\n",
    "# Convertir las columnas num√©ricas\n",
    "numeric_columns = column_headers[1:]\n",
    "for col in numeric_columns:\n",
    "    monthly_data_extracted[col] = pd.to_numeric(monthly_data_extracted[col], errors='coerce')\n",
    "\n",
    "monthly_data_extracted.set_index('Date', inplace=True)\n",
    "\n",
    "# Filtrar datos desde diciembre de 1994\n",
    "monthly_data_extracted = monthly_data_extracted.loc['1994-12-01':]\n",
    "\n",
    "# Calcular valores por unidad operativa\n",
    "monthly_data_per_unit = monthly_data_extracted.drop(columns=['Total_Operable_Units']).div(monthly_data_extracted['Total_Operable_Units'], axis=0)\n",
    "\n",
    "# Mostrar resultados\n",
    "st.write(f\"Mostrando datos de la hoja: {sheet_name} ya dividiendo por unidad operativa (Monthly Data Per Unit)\")\n",
    "st.write(monthly_data_per_unit.head(5))\n",
    "\n",
    "# Bot√≥n de descarga en Streamlit\n",
    "output = io.BytesIO()\n",
    "with pd.ExcelWriter(output, engine='xlsxwriter') as writer:\n",
    "    monthly_data_per_unit.to_excel(writer, sheet_name='Monthly Data Per Unit')\n",
    "    writer.close()\n",
    "\n",
    "st.download_button(\n",
    "    label=\"Descargar archivo procesado\",\n",
    "    data=output.getvalue(),\n",
    "    file_name=\"monthly_data_per_unit.xlsx\",\n",
    "    mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
    ")\n",
    "\n",
    "# üîπ Checkbox para permitir guardar en GitHub\n",
    "guardar_en_github = st.checkbox(\"Guardar archivos en GitHub\")\n",
    "\n",
    "if guardar_en_github:\n",
    "    # Asegurar que las subcarpetas existan\n",
    "    os.makedirs(ruta_sin_procesar, exist_ok=True)\n",
    "    os.makedirs(ruta_procesados, exist_ok=True)\n",
    "\n",
    "    if use_github == \"Subir un archivo propio\" and uploaded_file is not None:\n",
    "        # Guardar el archivo sin procesar en la carpeta correspondiente\n",
    "        ruta_archivo_original = os.path.join(ruta_sin_procesar, uploaded_file.name)\n",
    "        with open(ruta_archivo_original, \"wb\") as f:\n",
    "            f.write(uploaded_file.getbuffer())\n",
    "\n",
    "    # Guardar el archivo procesado en la carpeta de datos procesados\n",
    "    ruta_archivo_procesado = os.path.join(ruta_procesados, \"monthly_data_per_unit.xlsx\")\n",
    "    with pd.ExcelWriter(ruta_archivo_procesado, engine='xlsxwriter') as writer:\n",
    "        monthly_data_per_unit.to_excel(writer, sheet_name='Monthly Data Per Unit')\n",
    "        writer.close()\n",
    "\n",
    "    st.success(f\"Archivos guardados en:\\n- {ruta_sin_procesar}\\n- {ruta_procesados}\")\n",
    "\n",
    "    # COMMIT AUTOM√ÅTICO EN GIT\n",
    "    os.system(f\"git add {ruta_sin_procesar} {ruta_procesados}\")\n",
    "    os.system(f'git commit -m \"A√±adidos archivos sin procesar y procesados del {fecha_actual}\"')\n",
    "    os.system(\"git push origin main\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Descargar el archivo desde GitHub\n",
    "response = requests.get(url_scaler)\n",
    "if response.status_code == 200:\n",
    "    scaler = joblib.load(io.BytesIO(response.content))\n",
    "    print(\"Scaler cargado correctamente desde GitHub.\")\n",
    "else:\n",
    "    print(\"Error al descargar el scaler:\", response.status_code)\n",
    "\n",
    "\n",
    "\n",
    "# Funci√≥n para cargar modelos desde GitHub\n",
    "def cargar_modelo(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return joblib.load(io.BytesIO(response.content))\n",
    "    else:\n",
    "        print(f\"Error al descargar {url}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Cargar los modelos\n",
    "SARIMAX_Net_Summer_Capacity_MW = cargar_modelo(url_sarimax_mw)\n",
    "SARIMAX_Capacity_Factor_Percent = cargar_modelo(url_sarimax_capacity)\n",
    "modelo_ridge_NetGeneration = cargar_modelo(url_ridge)\n",
    "scalers = cargar_modelo(url_scaler)  # Cargamos los scalers\n",
    "\n",
    "# Verificar que monthly_data_per_unit exista antes de crear X e y\n",
    "if 'monthly_data_per_unit' in locals():\n",
    "\n",
    "    # Definir X (variables predictoras) e Y (variable objetivo)\n",
    "    X = monthly_data_per_unit.drop(columns=['Net_Generation_MWh', 'Share_of_Electricity_Percent'])\n",
    "    y = monthly_data_per_unit['Net_Generation_MWh']\n",
    "    \n",
    "    # Obtener el scaler correcto\n",
    "    scaler_X = scalers.get(\"Net_Summer_Capacity_MW\", None)\n",
    "\n",
    "    if scaler_X is None:\n",
    "        st.error(\"Error: No se encontr√≥ el scaler para 'Net_Summer_Capacity_MW'\")\n",
    "    else:\n",
    "        # Verificar columnas esperadas vs actuales\n",
    "        st.write(\"Las variables ex√≥genas son:\", X.columns.tolist())\n",
    "\n",
    "        # Asegurar que las columnas coinciden\n",
    "        for col in scaler_X.feature_names_in_:\n",
    "            if col not in X.columns:\n",
    "                X[col] = 0  # O usa np.nan para marcar los valores faltantes\n",
    "\n",
    "        # Reordenar las columnas\n",
    "        X = X[scaler_X.feature_names_in_]\n",
    "\n",
    "        # Aplicar la transformaci√≥n\n",
    "        X_scaled = scaler_X.transform(X)\n",
    "        \n",
    "else:\n",
    "    st.error(\"Error: `monthly_data_per_unit` no est√° definido. Aseg√∫rate de procesar correctamente los datos.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Selecci√≥n de a√±os a predecir\n",
    "a√±os_SARIMAX = st.number_input(\"¬øCu√°ntos a√±os quieres predecir?\", min_value=1, max_value=15, value=10, step=1, key = \"A√±os SARIMAX\")\n",
    "\n",
    "# Interfaz en Streamlit\n",
    "st.title(\"Predicci√≥n con SARIMAX de variables ex√≥genas\")\n",
    "\n",
    "# Checkbox para decidir si predecir con SARIMAX\n",
    "usar_sarimax = st.checkbox(\"¬øQuieres predecir variables ex√≥genas con SARIMAX?\")\n",
    "\n",
    "if usar_sarimax:\n",
    "\n",
    "\n",
    "    # Convertir a√±os a pasos (steps) de predicci√≥n\n",
    "    steps = a√±os_SARIMAX * 12  # 12 meses por a√±o\n",
    "\n",
    "    # Realizar predicciones con SARIMAX\n",
    "    pred_sarimax_Net_Summer = SARIMAX_Net_Summer_Capacity_MW.forecast(steps=steps)\n",
    "    pred_sarimax_Capacity = SARIMAX_Capacity_Factor_Percent.forecast(steps=steps)\n",
    "\n",
    "\n",
    "    # Inversa la transformaci√≥n\n",
    "    Net_summer_capacity_predict = scalers['Net_Summer_Capacity_MW'].inverse_transform(pred_sarimax_Net_Summer.values.reshape(-1, 1))\n",
    "    Capacity_factor_predict = scalers['Capacity_Factor_Percent'].inverse_transform(pred_sarimax_Capacity.values.reshape(-1, 1))\n",
    "    # Generar fechas futuras\n",
    "    future_dates = pd.date_range(start=pd.Timestamp.today().replace(day=1), periods=len(Net_summer_capacity_predict), freq=\"MS\").to_period('M')\n",
    "\n",
    "    # Convertir a DataFrame con √≠ndice de fechas\n",
    "    df_predictions = pd.DataFrame({\n",
    "        \"Fecha\": future_dates,\n",
    "        \"Predicci√≥n Net Summer Capacity MW\": Net_summer_capacity_predict.flatten(),  # Asegurar 1D\n",
    "        \"Predicci√≥n Capacity Factor Percent\": Capacity_factor_predict.flatten()  # Asegurar 1D\n",
    "    })\n",
    "\n",
    "    #Definimos el historico de datos\n",
    "    historico_x = monthly_data_per_unit[[\"Net_Summer_Capacity_MW\", \"Capacity_Factor_Percent\"]].copy()\n",
    "\n",
    "    # üîπ Asegurar que el √≠ndice del hist√≥rico es DatetimeIndex\n",
    "    if not isinstance(historico_x.index, pd.DatetimeIndex):\n",
    "        historico_x.index = historico_x.index.to_timestamp()\n",
    "\n",
    "    # Definir la columna Fecha como √≠ndice\n",
    "    df_predictions.set_index(\"Fecha\", inplace=True)\n",
    "    df_predictions.index =df_predictions.index.to_timestamp()\n",
    "\n",
    "    # üîç Depuraci√≥n antes de mostrar\n",
    "    st.write(\"Primeras filas del DataFrame de predicciones:\")\n",
    "    st.dataframe(df_predictions.head())\n",
    "\n",
    "\n",
    "\n",
    "    # üîπ Crear subgr√°ficos con dos filas\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=[\n",
    "        \"Predicci√≥n Net Summer Capacity MW\",\n",
    "        \"Predicci√≥n Capacity Factor Percent\"\n",
    "    ])\n",
    "\n",
    "    # üîπ Primer gr√°fico (Net Summer Capacity MW)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_predictions.index, \n",
    "        y=df_predictions[\"Predicci√≥n Net Summer Capacity MW\"], \n",
    "        mode='lines', \n",
    "        name=\"Predicci√≥n\", \n",
    "        line=dict(color=\"gold\")\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=historico_x.index, \n",
    "        y=historico_x[\"Net_Summer_Capacity_MW\"], \n",
    "        mode='lines', \n",
    "        name=\"Hist√≥rico\", \n",
    "        line=dict(color=\"green\")\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    # üîπ Segundo gr√°fico (Capacity Factor Percent)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_predictions.index, \n",
    "        y=df_predictions[\"Predicci√≥n Capacity Factor Percent\"], \n",
    "        mode='lines', \n",
    "        name=\"Predicci√≥n\", \n",
    "        line=dict(color=\"gold\")\n",
    "    ), row=2, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=historico_x.index, \n",
    "        y=historico_x[\"Capacity_Factor_Percent\"], \n",
    "        mode='lines', \n",
    "        name=\"Hist√≥rico\", \n",
    "        line=dict(color=\"darkgreen\")\n",
    "    ), row=2, col=1)\n",
    "\n",
    "    # üîπ Configurar el dise√±o del gr√°fico\n",
    "    fig.update_layout(\n",
    "        height=800, width=1000,  # Tama√±o personalizado\n",
    "        title_text=\"Predicciones de Energ√≠a Nuclear\",\n",
    "        showlegend=True,  # Mostrar leyenda en ambos gr√°ficos\n",
    "        legend=dict(\n",
    "            x=0,  # Posicionar a la izquierda\n",
    "            y=0.5,  # Posicionar arriba\n",
    "            bgcolor=\"rgba(0,0,0,0)\"  # Fondo transparente\n",
    "        ),\n",
    "        template=\"plotly_dark\"  # Modo oscuro\n",
    "    )\n",
    "    \n",
    "    # üîπ Mostrar el gr√°fico en Streamlit\n",
    "    st.plotly_chart(fig)\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Bot√≥n para descargar resultados como CSV\n",
    "    csv = df_predictions.to_csv(index=False).encode('utf-8')\n",
    "    st.download_button(\n",
    "        label=\"Descargar predicciones como CSV\",\n",
    "        data=csv,\n",
    "        file_name=\"predicciones_sarimax.csv\",\n",
    "        mime=\"text/csv\"\n",
    "    )\n",
    "else:\n",
    "    st.warning(\"No se realiza predicci√≥n con SARIMAX.\")\n",
    "# Interfaz en Streamlit\n",
    "st.title(\"Predicci√≥n con Ridge\")\n",
    "# Selecci√≥n de a√±os a predecir\n",
    "a√±os_Ridge = st.number_input(\"¬øCu√°ntos a√±os quieres predecir?\", min_value=1, max_value=15, value=10, step=1, key = \"A√±os Ridge\")\n",
    "\n",
    "# Checkbox para decidir si predecir con Ridge\n",
    "usar_ridge = st.checkbox(\"¬øQuieres predecir Net Generation MWh con Ridge?\")\n",
    "\n",
    "if usar_ridge:\n",
    "    # Definir Y_escalado correctamente\n",
    "    Y_escalado = y  # Asegurar que y ha sido escalado previamente\n",
    "    \n",
    "    # Convertir a√±os a pasos (steps) de predicci√≥n\n",
    "    steps = a√±os_Ridge * 12  # 12 meses por a√±o\n",
    "\n",
    "    # Mostrar configuraci√≥n del modelo\n",
    "    st.write(\"### üîç Configuraci√≥n del modelo Ridge\")\n",
    "    st.write(f\"Window size original del modelo: {modelo_ridge_NetGeneration.window_size}\")\n",
    "\n",
    "    # Ajustar window_size si hay menos datos de los esperados\n",
    "    window_size = modelo_ridge_NetGeneration.window_size\n",
    "    if len(Y_escalado) < window_size:\n",
    "        window_size = len(Y_escalado)  # Ajustamos al m√°ximo posible\n",
    "        st.warning(f\"‚ö†Ô∏è Window size ajustado a {window_size} porque no hay suficientes datos.\")\n",
    "\n",
    "    # Obtener la √∫ltima ventana de datos\n",
    "    last_window = Y_escalado[-modelo_ridge_NetGeneration.window_size:]\n",
    "    last_window.index = last_window.index.to_timestamp()\n",
    "    last_window = last_window.asfreq('MS')\n",
    "\n",
    "    #Usamos el modelo para predecir los a√±os seleccionados\n",
    "    pred_ridge_NetGeneration = modelo_ridge_NetGeneration.predict(steps=steps, last_window=last_window)\n",
    "\n",
    "    #Cambiamos de serie a DF\n",
    "    df_pred = pred_ridge_NetGeneration.rename_axis(\"Fecha\").rename(\"Predicci√≥n Net Generation MWh\").to_frame()\n",
    "\n",
    "    # Mostrar predicciones en tabla\n",
    "    st.write(\"###Predicciones Net Generation MWh\")\n",
    "    st.dataframe(df_pred.style.format(\"{:.2f}\"))\n",
    "    #st.dataframe(df_predictions)\n",
    "\n",
    "    # Graficar la serie original y la predicci√≥n suavizadas\n",
    "    st.write(\"###Comparaci√≥n entre Datos Originales y Predicci√≥n\")\n",
    "\n",
    "    # Asegurar que Y_escalado y pred_ridge_NetGeneration sean Series num√©ricas\n",
    "    Y_suavizado = Y_escalado.rolling(window=4, min_periods=1).mean()\n",
    "    pred_suavizado = pred_ridge_NetGeneration.rolling(window=4, min_periods=1).mean()\n",
    "\n",
    "\n",
    "    # ‚úÖ Eliminar valores NaN\n",
    "    Y_suavizado = Y_suavizado.dropna()\n",
    "    pred_suavizado = pred_suavizado.dropna()\n",
    "\n",
    "    # ‚úÖ Asegurar que el √≠ndice es un DatetimeIndex\n",
    "    if not isinstance(Y_suavizado.index, pd.DatetimeIndex):\n",
    "        Y_suavizado.index = Y_suavizado.index.to_timestamp()\n",
    "\n",
    "    if not isinstance(pred_suavizado.index, pd.DatetimeIndex):\n",
    "        pred_suavizado.index = pred_suavizado.index.to_timestamp()\n",
    "\n",
    "    # ‚úÖ Asegurar que los datos sean num√©ricos\n",
    "    Y_suavizado = Y_suavizado.astype(float)\n",
    "    pred_suavizado = pred_suavizado.astype(float)\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    # üîπ Crear la figura en Plotly\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # üîπ Agregar la serie original\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=Y_suavizado.index, \n",
    "        y=Y_suavizado, \n",
    "        mode='lines', \n",
    "        name=\"Datos Originales\", \n",
    "        line=dict(color=\"limegreen\")\n",
    "    ))\n",
    "\n",
    "    # üîπ Agregar la predicci√≥n\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pred_suavizado.index, \n",
    "        y=pred_suavizado, \n",
    "        mode='lines', \n",
    "        name=\"Predicci√≥n Ridge\", \n",
    "        line=dict(color=\"gold\")\n",
    "    ))\n",
    "\n",
    "    # üîπ Configurar el dise√±o del gr√°fico\n",
    "    fig.update_layout(\n",
    "        title=\"Comparaci√≥n entre Datos Originales y Predicci√≥n Ridge (Suavizado)\",\n",
    "        xaxis_title=\"Fecha\",\n",
    "        yaxis_title=\"MWh\",\n",
    "        legend=dict(\n",
    "            x=0,  # Posici√≥n en la izquierda\n",
    "            y=1.1,  # Posici√≥n arriba del gr√°fico\n",
    "            font=dict(color=\"white\"),  # Letras blancas en la leyenda\n",
    "            bgcolor=\"rgba(0,0,0,0)\"  # Fondo transparente para la leyenda\n",
    "        ),\n",
    "        template=\"plotly_dark\",  # Fondo negro con letras blancas\n",
    "        width=800, height=500  # Ajuste de tama√±o para mejor visualizaci√≥n\n",
    "        )\n",
    "\n",
    "    # üîπ Mostrar la gr√°fica en Streamlit\n",
    "    st.plotly_chart(fig)\n",
    "\n",
    "\n",
    "    # Bot√≥n para descargar predicciones en CSV\n",
    "    csv = df_predictions.to_csv(index=False).encode('utf-8')\n",
    "    st.download_button(\n",
    "        label=\"üì• Descargar predicciones como CSV\",\n",
    "        data=csv,\n",
    "        file_name=\"predicciones_ridge.csv\",\n",
    "        mime=\"text/csv\"\n",
    "    )\n",
    "\n",
    "    # Preguntar si el usuario quiere guardar los datos en GitHub\n",
    "    guardar_github = st.checkbox(\"¬øQuieres guardar las predicciones en GitHub?\")\n",
    "    if guardar_github:\n",
    "        import os\n",
    "\n",
    "        # Definir ruta de guardado\n",
    "        ruta_base = \"Datos/Predicciones Ridge\"\n",
    "        ruta_subcarpeta = os.path.join(ruta_base, pd.Timestamp.today().strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "        # Asegurar que la subcarpeta existe\n",
    "        os.makedirs(ruta_subcarpeta, exist_ok=True)\n",
    "\n",
    "        # Guardar el archivo en la carpeta\n",
    "        ruta_archivo = os.path.join(ruta_subcarpeta, \"predicciones_ridge.csv\")\n",
    "        df_predictions.to_csv(ruta_archivo, index=False)\n",
    "\n",
    "        # Subir a GitHub con Git\n",
    "        os.system(f\"git add {ruta_archivo}\")\n",
    "        os.system(f'git commit -m \"A√±adidas predicciones Ridge del {pd.Timestamp.today().strftime(\"%Y-%m-%d\")}\"')\n",
    "        os.system(\"git push origin main\")\n",
    "\n",
    "        st.success(f\"üì§ Predicciones guardadas en GitHub: {ruta_archivo}\")\n",
    "\n",
    "else:\n",
    "    st.warning(\"No se realiz√≥ predicci√≥n con Ridge.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
